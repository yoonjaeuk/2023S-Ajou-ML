{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoonjaeuk/2023S-Ajou-ML/blob/main/alopecia_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xpx9qGvVSQE"
      },
      "source": [
        "## 1. Data Loader\n",
        "    * code 파일 디렉토리 위치에, 'train_set, test_set'이라는 이름으로 이미지 파일을 저장합니다.\n",
        "    * alopecia 파일 디렉토리를 기존대로 4개로 유지합니다. (이 상태로 아래 코드에 따라 로딩하면, output이 4개가 됩니다.)\n",
        "    * 혹은 (이미지 파일을 2개로 합쳐서 output을 2개로 할 수도 있습니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUlpTokyVSQH",
        "outputId": "590582ec-c246-4504-c522-0fb3d3597468"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-21-faf4a8d7b610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "trans = transforms.Compose([transforms.Resize((640, 480)), transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=\"./train_set\",transform=trans)\n",
        "test_dataset= torchvision.datasets.ImageFolder(root=\"./test_set\", transform=trans)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klrPoJx0VSQJ"
      },
      "source": [
        "## 2. Net Implementation\n",
        "    * 자유롭게 구성해볼 수 있겠습니다. (저는 일단 단순하게 구현해봤습니다 -> 현재 정답률이 74% 정도로 나오는 수준으로 구성되어 있습니다)\n",
        "    * data load에서 tensor size와 호환되도록 구성하셔야 합니다. (혹은 data load를 바꾸셔도 됩니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku4I_RxeVSQK"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # [ NET Structure ]\n",
        "\n",
        "        # input: 320*240*3\n",
        "        # conv1 with batch nomalization: 640*480*3 -> 636*476*10 (kernel size = 5)\n",
        "        # pool1: 636*476*10 -> 318*238(*10)\n",
        "        # conv2 with batch nomalization: 318*238 -> 314*234 (kernel size = 5)\n",
        "        # pool2: 314*234 -> 157*117\n",
        "        # conv3 with batch nomalization: 157*117 -> 153*113 (kernel size = 5)\n",
        "        # pool3: 153*113 -> 76*56\n",
        "        # conv4 with batch nomalization: 76*56 -> 74*54 (kernel size = 5)\n",
        "        # pool4: 74*54 -> 37*27\n",
        "        # conv5 with batch nomalization: 37*27 -> 33*23 (kernel size = 5)\n",
        "        # pool5: 33*23 -> 16*11\n",
        "        # flatten: 16*11*10 -> 1760\n",
        "        # fc6 with batch nomalization: 1760 -> 400\n",
        "        # fc7 with batch nomalization: 400 -> 80\n",
        "        # fc8 with batch nomalizatio: 80 -> 20\n",
        "        # fc9: 20 -> 4\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "        self.bn1 = nn.BatchNorm2d(10)\n",
        "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5)\n",
        "        self.bn2 = nn.BatchNorm2d(10)\n",
        "        self.conv3 = nn.Conv2d(10, 10, kernel_size=5)\n",
        "        self.bn3 = nn.BatchNorm2d(10)\n",
        "        self.conv4 = nn.Conv2d(10, 10, kernel_size=5)\n",
        "        self.bn4 = nn.BatchNorm2d(10)\n",
        "        self.conv5 = nn.Conv2d(10, 10, kernel_size=5)\n",
        "        self.bn5 = nn.BatchNorm2d(10)\n",
        "        self.fc6 = nn.Linear(1760, 400)\n",
        "        self.bn6 = nn.BatchNorm1d(400)\n",
        "        self.fc7 = nn.Linear(400, 80)\n",
        "        self.bn7 = nn.BatchNorm1d(80)\n",
        "        self.fc8 = nn.Linear(80, 20)\n",
        "        self.bn8 = nn.BatchNorm1d(20)\n",
        "        self.fc9 = nn.Linear(20, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
        "        x = torch.nn.Flatten()(x) # flatten all dimensions except batch\n",
        "        x = F.relu(self.bn6(self.fc6(x)))\n",
        "        x = F.relu(self.bn7(self.fc7(x)))\n",
        "        x = F.relu(self.bn8(self.fc8(x)))\n",
        "        x = F.softmax(self.fc9(x), dim=1)\n",
        "        return x\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ3Z38sHVSQL"
      },
      "source": [
        "## 3. Train and Test\n",
        "    * mps는 mac에서 gpu를 이용하기 위한 코드입니다. 따라서 위도우 사용자 혹은 코랩 이용자의 경우는 \"cuda\"로 코드를 바꿔서 진행하시면 gpu를 이용하실 수 있습니다. (HW4 참고)\n",
        "    * learning rate, optimizer 등은 자유롭게 구성하시면 좋을 것 같습니다.\n",
        "    * train 과정과 test과정이 실시간으로 드러나도록 구현했고, top1, top2-Accuracy를 출력했습니다.\n",
        "    * top1은 총 4개의 예측 확률값 중 가장 높은 것이 정답과 일치하는 비율이고, top2는 총 4개의 예측 확률값 중 가장 높은 2개 중에 정답이 속하는 비율입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz-d9eq-VSQL",
        "outputId": "d25039ef-a182-48d8-d258-15002d5701fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "NVIDIA GeForce RTX 3050\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name())\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoSekCAvVSQM"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "cuda.get_current_device().reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvNe2HjhVSQM",
        "outputId": "c30cc69c-51a8-4715-d308-a19e503160ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Devise: cuda]\n",
            "-----------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Train Epoch: 1] loss = 1.03730977: 100%|██████████| 579/579 [02:06<00:00,  4.57it/s]   \n",
            "[Train Epoch: 2] loss = 0.997681737: 100%|██████████| 579/579 [01:56<00:00,  4.98it/s]  \n",
            "[Train Epoch: 3] loss = 0.99053216: 100%|██████████| 579/579 [01:54<00:00,  5.07it/s]   \n",
            "[Train Epoch: 4] loss = 0.984775126: 100%|██████████| 579/579 [01:56<00:00,  4.96it/s]  \n",
            "[Train Epoch: 5] loss = 0.978656113: 100%|██████████| 579/579 [01:57<00:00,  4.95it/s]  \n",
            "[Train Epoch: 6] loss = 0.97161305: 100%|██████████| 579/579 [01:56<00:00,  4.97it/s]   \n",
            "[Train Epoch: 7] loss = 0.963501513: 100%|██████████| 579/579 [01:56<00:00,  4.97it/s]  \n",
            "[Train Epoch: 8] loss = 0.95057106: 100%|██████████| 579/579 [01:56<00:00,  4.96it/s]   \n",
            "[Train Epoch: 9] loss = 0.943243265: 100%|██████████| 579/579 [01:56<00:00,  4.96it/s]  \n",
            "[Train Epoch: 10] loss = 0.935276747: 100%|██████████| 579/579 [01:56<00:00,  4.96it/s]  \n",
            "[Train Epoch: 11] loss = 0.925840199: 100%|██████████| 579/579 [01:56<00:00,  4.97it/s]  \n",
            "[Train Epoch: 12] loss = 0.918646276: 100%|██████████| 579/579 [01:56<00:00,  4.96it/s]  \n",
            "[Train Epoch: 13] loss = 0.909673095: 100%|██████████| 579/579 [01:56<00:00,  4.96it/s]  \n",
            "[Train Epoch: 14] loss = 0.904518425: 100%|██████████| 579/579 [01:56<00:00,  4.95it/s]  \n",
            "[Train Epoch: 15] loss = 0.897865951: 100%|██████████| 579/579 [01:56<00:00,  4.95it/s]  \n",
            "[Train Epoch: 16] loss = 0.888820708: 100%|██████████| 579/579 [01:56<00:00,  4.97it/s]  \n",
            "[Train Epoch: 17] loss = 0.88406235: 100%|██████████| 579/579 [01:56<00:00,  4.96it/s]   \n",
            "[Train Epoch: 18] loss = 0.880873263: 100%|██████████| 579/579 [02:12<00:00,  4.36it/s]  \n",
            "[Train Epoch: 19] loss = 0.872886121: 100%|██████████| 579/579 [01:55<00:00,  5.00it/s]  \n",
            "[Train Epoch: 20] loss = 0.865035474: 100%|██████████| 579/579 [01:55<00:00,  5.00it/s]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Test]: 100%|██████████| 166/166 [00:31<00:00,  5.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Accuracy: 72.598335855 ([3839/5288])\n",
            "Top-2 Accuracy: 85.760211800 ([4535/5288])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"[Devise: %s]\" %device)\n",
        "print(\"-----------------------------------------------------------------------------\")\n",
        "net = Net()\n",
        "net = net.to(device)\n",
        "net = torch.nn.DataParallel(net)\n",
        "\n",
        "learning_rate = 0.01\n",
        "# learning_rate = 0.005\n",
        "epochs = 20\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def test(model, testloader):\n",
        "    top1_correct = 0\n",
        "    top2_correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pbar1 = tqdm(test_loader, total=len(test_loader))\n",
        "        for data, target in pbar1:\n",
        "            if device == \"cuda\":\n",
        "                data = data.to(device)\n",
        "                target = target.to(device)\n",
        "            out = net(data)\n",
        "\n",
        "            _, top1_pred = torch.max(out, 1)\n",
        "            total += target.size(0)\n",
        "            top1_correct += (top1_pred == target).sum().item()\n",
        "\n",
        "            _, top2_pred = torch.topk(out, 2, dim=1)\n",
        "            top2_correct += sum([1 for i in range(target.size(0)) if target[i] in top2_pred[i]])\n",
        "            pbar1.set_description('[Test]')\n",
        "\n",
        "        top1_accuracy = 100.0 * top1_correct / total\n",
        "        top2_accuracy = 100.0 * top2_correct / total\n",
        "\n",
        "    print(\"Top-1 Accuracy: %.9f ([%d/%d])\" %(top1_accuracy, top1_correct, total))\n",
        "    print(\"Top-2 Accuracy: %.9f ([%d/%d])\" %(top2_accuracy, top2_correct, total))\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    avg_loss = 0\n",
        "    pbar2 = tqdm(train_loader, total=len(train_loader))\n",
        "    for data, target in pbar2:\n",
        "        if device == \"cuda\":\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "        pred = net(data)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(pred, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss += loss / len(train_loader)\n",
        "        pbar2.set_description('[Train Epoch: {:>1}] loss = {:>.9}'.format(epoch + 1, avg_loss))\n",
        "\n",
        "print(\"-----------------------------------------------------------------------------\")\n",
        "net.eval()\n",
        "test(net, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOraY8boVSQM"
      },
      "source": [
        "## 4. Net structure & #params\n",
        "    * Net의 구조와 parameter 개수를 표현할 수 있도록 했습니다.\n",
        "    * 자기가 구성한 입력 size를 summary함수의 input에 넣어주셔야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkEohaq0VSQN"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "net.to(\"cpu\")\n",
        "summary(net, (3, 640, 480))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}